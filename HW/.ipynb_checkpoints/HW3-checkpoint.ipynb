{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 3:  Master Regression on the Ames Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework is meant to be a more open ended, exploratory way for students to complete their assignment for Homework project #3. \n",
    "\n",
    "Instead of doing the pre-assigned tasks in the other projects given, you can use this homework as a chance to develop your own model using the Ames Housing dataset, as discussed here:  https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your homework assignment will be to try and get the best leaderboard score that you can, using techniques learned so far in class, in addition to whatever else you find online.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will be a continuation of what was covered in class 14 when we made our first submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In so doing, present the following 5 questions to class when you are finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your final leaderboard score?  How many submissions did it take for you to get there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final score was 0.15286. It took me about 5 submissions to get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What types of techniques did you use?  Which ones worked best, which ones didn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first method was increasing the number of features. I did some data exploration to find some interesting categorical features and then encoded them. I used a combination of one-hot encoding and ordinal encoding. Just the adding of features alone made a huge improvement to the baseline score.\n",
    "\n",
    "After that I tried using random forests, ridge and lasso regression. I wanted to see what would yield the best results and continue to focus on that type of model. The way I choose the model was to run cross validation on my initial training set. The model with the highest mean score was the winner.Random forests were the most effective so I focused on it. Their r squared value was about 0.02-0.03 higher than the linear models.\n",
    "\n",
    "Once I locked in a model to work with, I ran some tests to see what the optimal parameters were. I tested min_leaf_size, max_features, and n_estimators. I ran these tests many times as I started working with the data so that the parameters were always optimal.\n",
    "\n",
    "I also standardized the numerical data in the data set to see if that would improve the model. There was barely any improvement but it was worth exploring, and simple to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What new features or modifications did you make to your data that helped your score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the increase to my score came from features such as the neighborhood, Building type, Central air, Heating quality, and a few others. \n",
    "\n",
    "Tuning and standardizing were also able to improve my score but not as dramatically as adding relevant features to the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How reliable was the association between your validation and test scores?  What steps did you take to correct this measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation scores were higher than the test scores. Not surprising given that the model would most likely encounter some anamolies that it didn't see in the training data. I just made sure to test in a variety of ways and made sure to test different fold options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What surprised you the most when it came to your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain features that I thought would have an impact actually lowered my score. I was also surprised how much of a jump the score made with the initial features, but then was difficult to improve from there on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you could, what would you like to explore in the future with regards to this sort of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to take a different approach with classification and see if encoding the categorical variables in different ways would improve my score at all. I'd also like to use a random forest library that can handle categorical data straight away. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
